{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mixem\n",
    "import scipy\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class Poisson(mixem.distribution.Distribution):\n",
    "\n",
    "    def __init__(self, lambda_) -> None:\n",
    "        super().__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def pmf(self, x):\n",
    "        return np.exp( np.log(self.lambda_)*x  - self.lambda_ - gammaln(x+1) )\n",
    "\n",
    "    def estimate_parameters(self, data, weights):\n",
    "        prob = self.pmf(data)\n",
    "        self.lambda_ = np.sum(prob*data)/np.sum(prob)\n",
    "\n",
    "    def log_density(self, data):\n",
    "        return np.log(self.pmf(data))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Poisson[lambda={lbd:.4g}]\".format(lbd=self.lambda_)\n",
    "\n",
    "class logGMM:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        self.weights = [] \n",
    "        self.distributions = []\n",
    "        self.data = []\n",
    "\n",
    "    def fit_logGMM(self, data):\n",
    "        data = np.array(data)\n",
    "        self.data = data[data>0.0]\n",
    "\n",
    "        # Fit and plot log gaussian mixture\n",
    "        self.weights, self.distributions, log_likelihood = mixem.em(self.data, [\n",
    "            mixem.distribution.LogNormalDistribution(mu=-6, sigma=2.4),\n",
    "            mixem.distribution.LogNormalDistribution(mu=-2.7, sigma=0.1),\n",
    "            # mixem.distribution.NormalDistribution(mu=300, sigma=50),\n",
    "        ], initial_weights=[0.8, 0.2], progress_callback=None)\n",
    "\n",
    "    def get_pdf(self, x_axis):\n",
    "        return mixem.probability(x_axis, self.weights, self.distributions)\n",
    "\n",
    "    def find_midpoint(self, interval=[1e-3, 1e-1]):\n",
    "        x_search = np.linspace(interval[0], interval[1], 10000)\n",
    "\n",
    "        pdf1 = np.exp(self.distributions[0].log_density(x_search))\n",
    "        pdf2 = np.exp(self.distributions[1].log_density(x_search))\n",
    "\n",
    "        x_max_1 = np.argmax(pdf1)\n",
    "        x_max_2 = np.argmax(pdf2)\n",
    "\n",
    "        if x_max_1 < x_max_2:\n",
    "            interval = [x_max_1, x_max_2]\n",
    "        else:\n",
    "            interval = [x_max_2, x_max_1]\n",
    "\n",
    "        pdf_diff = np.abs(pdf1-pdf2)[interval[0]:interval[1]]\n",
    "        if pdf_diff.size >0:\n",
    "            return x_search[np.argmin(pdf_diff)]\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def get_mode(self, dist_idx):\n",
    "        return np.exp(self.distributions[dist_idx].mu - self.distributions[dist_idx].sigma**2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../../data/construct_sequence_mut_rates.json')\n",
    "\n",
    "df = df[df['sample']=='18DMS'].reset_index(drop=True)\n",
    "\n",
    "signals = np.stack(df['mut_rates']).astype(float)\n",
    "signals = np.nan_to_num(signals)\n",
    "\n",
    "sequences = np.array([ list(seq) for seq in df['sequence']])\n",
    "print(\"Number of sequences\", len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking where is signal in sequence\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "MS2_start = boundary['MS2'](df['sequence'][0])[0]\n",
    "ROI_start = boundary['ROI'](df['sequence'][0])[0]\n",
    "signal_before_ROI = signals[:, MS2_start:ROI_start]\n",
    "\n",
    "signals_after_ROI = []\n",
    "signals_ROI = []\n",
    "seqs_ROI = []\n",
    "for seq, signal in zip(sequences, signals):\n",
    "    seq_str = ''.join(seq)\n",
    "    signal_after_ROI = np.array(signal[boundary['TC2'](seq_str)[0]:boundary['LAH'](seq_str)[1] ]).astype(float)\n",
    "    signals_after_ROI.append( np.nan_to_num(signal_after_ROI) )\n",
    "\n",
    "\n",
    "    signal_ROI = np.array(signal[boundary['ROI'](seq_str)[0]:boundary['ROI'](seq_str)[1] ]).astype(float)\n",
    "    seq_ROI = np.array(seq[boundary['ROI'](seq_str)[0]:boundary['ROI'](seq_str)[1] ])\n",
    "    signals_ROI.append( np.nan_to_num(signal_ROI) )\n",
    "    seqs_ROI.append(seq_ROI)\n",
    "signals_after_ROI = np.array(signals_after_ROI)\n",
    "\n",
    "streched_ROI_win = max([len(signal) for signal in signals_ROI])\n",
    "streched_ROI_signals = np.zeros( (len(signals_ROI), streched_ROI_win) )\n",
    "for i, signal in enumerate(signals_ROI):\n",
    "    assert np.isnan(signal).any() == False, 'nan at {}'.format(i)\n",
    "    f_signal = interpolate.interp1d(np.arange(len(signal)), signal)\n",
    "    streched_ROI_signals[i] = f_signal(np.linspace(0, len(signal)-1, streched_ROI_win))\n",
    "\n",
    "fig = go.Figure()\n",
    "idx_start = ROI_start-MS2_start\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Before ROI',\n",
    "    x=np.arange(idx_start), y=np.mean(signal_before_ROI, axis=0),\n",
    "    error_y=dict(type='data', array=np.std(signal_before_ROI, axis=0))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='ROI (streched)',\n",
    "    x=np.arange(idx_start, idx_start+streched_ROI_win), y=np.mean(streched_ROI_signals, axis=0),\n",
    "    error_y=dict(type='data', array=np.std(streched_ROI_signals, axis=0))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='After ROI',\n",
    "    x=np.arange(idx_start+streched_ROI_win, idx_start+streched_ROI_win+20), y=np.mean(signals_after_ROI, axis=0),\n",
    "    error_y=dict(type='data', array=np.std(signals_after_ROI, axis=0))\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(title='Average mutation rate accross all construct', barmode='group', xaxis_title='nucleotide position', yaxis_title='mutation rate')\n",
    "fig.show()\n",
    "\n",
    "print('Average std before ROI', np.mean(np.std(signal_before_ROI, axis=0)))\n",
    "print('Average std in ROI', np.mean(np.std(streched_ROI_signals, axis=0)))\n",
    "print('Average std after ROI', np.mean(np.std(signals_after_ROI, axis=0)))\n",
    "\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/average_signal.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes on sampels:\n",
    "# 18 and 470\n",
    "# 19 and 472\n",
    "\n",
    "# 33, 36 are bad\n",
    "\n",
    "# Results\n",
    "# Across sample 18DMS\n",
    "# Average std before ROI 0.009616456641118194\n",
    "# Average std in ROI 0.019736332473797833\n",
    "# Average std after ROI 0.011510102386244694\n",
    "\n",
    "# Across all samples\n",
    "# Average std before ROI 0.01080475276617488\n",
    "# Average std in ROI 0.01984380795355725\n",
    "# Average std after ROI 0.014755924434694043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataset of signals for various sliding windows\n",
    "mu_thresh = 0.08\n",
    "\n",
    "def create_dataset(seq_list, signal_list, win_len):\n",
    "    # The dataset is a dictionary, each key corresponding to one possible window of bases\n",
    "\n",
    "    # Go over each sequence, extract sliding window array, and find matches with key window\n",
    "    dataset = {}\n",
    "    n_points = 0\n",
    "    for sequence, signal in zip(seq_list, signal_list):\n",
    "        idx_win = np.arange(len(sequence)-win_len+1)\n",
    "        seq_triplets = sequence[idx_win[:, np.newaxis] + np.arange(win_len)]\n",
    "        seq_triplets = seq_triplets[(seq_triplets[:, 1]=='A') | (seq_triplets[:, 1]=='C')]\n",
    "\n",
    "        # for seq_window, seq_key in zip(seq_window_set, seq_window_set_key):\n",
    "        for i, triplet in enumerate(seq_triplets):\n",
    "            key = ''.join(triplet)\n",
    "\n",
    "            if signal[i+1] < mu_thresh:\n",
    "                if key in dataset:\n",
    "                    dataset[key].append(signal[i+1])\n",
    "                else:\n",
    "                    dataset[key] = [signal[i+1]]\n",
    "                \n",
    "                n_points += 1\n",
    "            \n",
    "\n",
    "    print('Length of curated dataset', n_points)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, max_iter=1000, covariance_type = 'full')\n",
    "def fit_GMM(data):\n",
    "    gmm.fit(np.array(data).reshape(-1,1))\n",
    "    x_axis = np.linspace(min(data), max(data), 500)\n",
    "    pdf = np.zeros_like(x_axis)\n",
    "    for i_c in range(2):\n",
    "        pdf += norm.pdf(x_axis, gmm.means_[i_c], np.sqrt(float(gmm.covariances_[i_c])))*gmm.weights_[i_c]\n",
    "\n",
    "    return x_axis, pdf\n",
    "\n",
    "win_len = 3\n",
    "dataset = create_dataset(sequences, signals, win_len)\n",
    "print(\"Length of full dataset\", sequences.shape[0]*(sequences.shape[1]-(win_len-1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_signal = np.concatenate(signals).ravel()\n",
    "dataset['full'] = full_signal[full_signal < mu_thresh]\n",
    "\n",
    "dist = logGMM()\n",
    "dist.fit_logGMM(data=dataset['full'])\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Histogram(x=dataset['full'], histnorm='probability density', showlegend=False) )\n",
    "\n",
    "x_axis = np.linspace(min(dataset['full']), max(dataset['full']), 500)\n",
    "fig.add_trace( go.Scatter(x=x_axis, y=dist.get_pdf(x_axis), marker_color='red') )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Full dataset\"+' ({:.0f} points) | Mu low:{:.2e} | Mu mid: {:.2e} | Mu high: {:.2e}'.format(\n",
    "                            len(dataset['full']), \n",
    "                            dist.get_mode(0), dist.find_midpoint(), dist.get_mode(1)\n",
    "                            ),\n",
    "    xaxis_title=\"Mutation rate\",\n",
    "    yaxis_title=\"Probability density\")\n",
    "fig.update_yaxes(range=[0, 10*dist.get_pdf(dist.get_mode(1))[0]])\n",
    "\n",
    "fig.show()\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/logGMM/full_histogram.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['A'] = []\n",
    "dataset['C'] = []\n",
    "\n",
    "for key, value in dataset.items():\n",
    "    if len(key) == 3:\n",
    "        if key[1] =='A':\n",
    "            dataset['A'] += value\n",
    "\n",
    "        if key[1] =='C':\n",
    "            dataset['C'] += value\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "for i_b, key in enumerate(['A', 'C']):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=dataset[key], histnorm='probability density', showlegend=False) , row=1, col=i_b+1)\n",
    "\n",
    "    x_axis = np.linspace(min(dataset[key]), max(dataset[key]), 500)\n",
    "    dist.fit_logGMM(data=dataset[key])\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=x_axis,\n",
    "            y=dist.get_pdf(x_axis),\n",
    "            showlegend=False,\n",
    "            marker_color = px.colors.qualitative.D3[2]\n",
    "        ), row=1, col=i_b+1)\n",
    "\n",
    "    fig.update_xaxes(title_text=key+' ({:.0f} points) | Mu low:{:.2e} | Mu mid: {:.2e} | Mu high: {:.2e}'.format(\n",
    "                            len(dataset[key]), \n",
    "                            dist.get_mode(0), dist.find_midpoint(), dist.get_mode(1)\n",
    "                            ), row=1, col=i_b+1)\n",
    "    fig.update_yaxes(range=[0, 10*dist.get_pdf(dist.get_mode(1))[0]], row=1, col=i_b+1)\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    title_text=\"Histogram of DMS signals for A and C\")\n",
    "fig.show()\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/logGMM/A_C_histogram.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "var = []\n",
    "weight = []\n",
    "fig = make_subplots(rows=len(dataset)//2, cols=2)\n",
    "\n",
    "row_A = 1\n",
    "row_C = 1\n",
    "for i, key in enumerate(dataset.keys()):\n",
    "    if len(key) == 3:\n",
    "\n",
    "        col = 1 if key[1]=='A' else 2\n",
    "\n",
    "        if key[1]=='A':\n",
    "            row = row_A\n",
    "            row_A +=1\n",
    "            color= px.colors.qualitative.Plotly[1]\n",
    "        else:\n",
    "            row = row_C\n",
    "            row_C +=1\n",
    "            color= px.colors.qualitative.Plotly[0]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=dataset[key], showlegend=False, histnorm='probability density', marker_color=color) , row=row, col=col)\n",
    "\n",
    "        x_axis = np.linspace(min(dataset[key]), max(dataset[key]), 500)\n",
    "        dist.fit_logGMM(data=dataset[key])\n",
    "\n",
    "        # mean.append([mean for _, mean in sorted(zip(gmm.means_.T[0], gmm.means_.T[0])) ])\n",
    "        # var.append([var for _, var in sorted(zip(gmm.means_.T[0], gmm.covariances_.T[0][0])) ])\n",
    "        # weight.append([w for _, w in sorted(zip(gmm.means_.T[0], gmm.weights_)) ])\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_axis,\n",
    "            y=dist.get_pdf(x_axis),\n",
    "            showlegend=False,\n",
    "            marker_color = px.colors.qualitative.D3[2]\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text=key+' ({:.0f} points) | Mu low:{:.2e} | Mu mid: {:.2e} | Mu high: {:.2e}'.format(\n",
    "                            len(dataset[key]), \n",
    "                            dist.get_mode(0), dist.find_midpoint(), dist.get_mode(1)\n",
    "                            ), row=row, col=col)\n",
    "\n",
    "        fig.update_yaxes(range=[0, 10*dist.get_pdf(dist.get_mode(1))[0]], row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=4000,\n",
    "    width=1400,\n",
    "    title_text=\"Histogram of DMS signals for each triplet bases\")\n",
    "fig.show()\n",
    "\n",
    "mean = np.array(mean)\n",
    "var = np.array(var)\n",
    "weight = np.array(weight)\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/logGMM/triplet_histogram.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for mu, v, w in zip(mean, var, weight):\n",
    "    fig.add_trace( go.Scatter(x = x_axis, y=norm.pdf(x_axis, mu[0], np.sqrt(v[0]))*w[0], marker_color='red', showlegend=False))\n",
    "    fig.add_trace( go.Scatter(x = x_axis, y=norm.pdf(x_axis, mu[1], np.sqrt(v[1]))*w[1], marker_color='blue', showlegend=False))\n",
    "\n",
    "# fig.update_yaxes(type='log', range=[0,2])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=2)\n",
    "\n",
    "for r, stat in enumerate([mean, var, weight]):\n",
    "\n",
    "    for i in range(stat.shape[1]):\n",
    "        fig.add_trace( go.Histogram(x=stat[:,i], showlegend=False) , row=r+1, col=i+1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1200)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da229f0528e1c0d1c0b9dd42b2435d18e9f382f2b763d9e722ef981a0e650149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
