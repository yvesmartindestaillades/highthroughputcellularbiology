{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing documentation for parameter 'bv_files' of function 'run'\n",
      "WARNING:root:Missing documentation for parameter 'sample' of function 'run'\n",
      "WARNING:root:Missing documentation for parameter 'clustering_file' of function 'run'\n",
      "WARNING:root:Missing documentation for parameter 'rnastructure_path' of function 'run'\n",
      "WARNING:root:Missing documentation for parameter 'verbose' of function 'run'\n",
      "WARNING:root:Missing documentation for parameter 'rnastructure_path' of function 'run'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "from config import *\n",
    "from util import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ../../data/reference_sequence_mut_rates.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m'\u001b[39;49m\u001b[39m../../data/reference_sequence_mut_rates.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39msample\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m18DMS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m signals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(df[\u001b[39m'\u001b[39m\u001b[39mmut_rates\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/src/highthroughputcellularbiology/venv/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/src/highthroughputcellularbiology/venv/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/src/highthroughputcellularbiology/venv/lib/python3.11/site-packages/pandas/io/json/_json.py:733\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[1;32m    734\u001b[0m     path_or_buf,\n\u001b[1;32m    735\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[1;32m    736\u001b[0m     typ\u001b[39m=\u001b[39;49mtyp,\n\u001b[1;32m    737\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    738\u001b[0m     convert_axes\u001b[39m=\u001b[39;49mconvert_axes,\n\u001b[1;32m    739\u001b[0m     convert_dates\u001b[39m=\u001b[39;49mconvert_dates,\n\u001b[1;32m    740\u001b[0m     keep_default_dates\u001b[39m=\u001b[39;49mkeep_default_dates,\n\u001b[1;32m    741\u001b[0m     numpy\u001b[39m=\u001b[39;49mnumpy,\n\u001b[1;32m    742\u001b[0m     precise_float\u001b[39m=\u001b[39;49mprecise_float,\n\u001b[1;32m    743\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[1;32m    744\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    745\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[1;32m    746\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    747\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    748\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[1;32m    749\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    750\u001b[0m     encoding_errors\u001b[39m=\u001b[39;49mencoding_errors,\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[1;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m~/src/highthroughputcellularbiology/venv/lib/python3.11/site-packages/pandas/io/json/_json.py:818\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlines:\n\u001b[1;32m    816\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnrows can only be passed if lines=True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 818\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m    819\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m~/src/highthroughputcellularbiology/venv/lib/python3.11/site-packages/pandas/io/json/_json.py:874\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    866\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[1;32m    867\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    868\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    869\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    873\u001b[0m ):\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m filepath_or_buffer\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File ../../data/reference_sequence_mut_rates.json does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('../../data/reference_sequence_mut_rates.json')\n",
    "\n",
    "df = df[df['sample']=='18DMS'].reset_index(drop=True)\n",
    "\n",
    "signals = np.stack(df['mut_rates']).astype(float)\n",
    "signals = np.nan_to_num(signals)\n",
    "\n",
    "sequences = np.array([ list(seq) for seq in df['sequence']])\n",
    "print(\"Number of sequences\", len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking where is signal in sequence\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "MS2_start = boundary['MS2'](df['sequence'][0])[0]\n",
    "ROI_start = boundary['ROI'](df['sequence'][0])[0]\n",
    "signal_before_ROI = signals[:, MS2_start:ROI_start]\n",
    "\n",
    "signals_after_ROI = []\n",
    "signals_ROI = []\n",
    "seqs_ROI = []\n",
    "for seq, signal in zip(sequences, signals):\n",
    "    seq_str = ''.join(seq)\n",
    "    signal_after_ROI = np.array(signal[boundary['TC2'](seq_str)[0]:boundary['LAH'](seq_str)[1] ]).astype(float)\n",
    "    signals_after_ROI.append( np.nan_to_num(signal_after_ROI) )\n",
    "\n",
    "\n",
    "    signal_ROI = np.array(signal[boundary['ROI'](seq_str)[0]:boundary['ROI'](seq_str)[1] ]).astype(float)\n",
    "    seq_ROI = np.array(seq[boundary['ROI'](seq_str)[0]:boundary['ROI'](seq_str)[1] ])\n",
    "    signals_ROI.append( np.nan_to_num(signal_ROI) )\n",
    "    seqs_ROI.append(seq_ROI)\n",
    "signals_after_ROI = np.array(signals_after_ROI)\n",
    "\n",
    "streched_ROI_win = max([len(signal) for signal in signals_ROI])\n",
    "streched_ROI_signals = np.zeros( (len(signals_ROI), streched_ROI_win) )\n",
    "for i, signal in enumerate(signals_ROI):\n",
    "    assert np.isnan(signal).any() == False, 'nan at {}'.format(i)\n",
    "    f_signal = interpolate.interp1d(np.arange(len(signal)), signal)\n",
    "    streched_ROI_signals[i] = f_signal(np.linspace(0, len(signal)-1, streched_ROI_win))\n",
    "\n",
    "fig = go.Figure()\n",
    "idx_start = ROI_start-MS2_start\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Before ROI',\n",
    "    x=np.arange(idx_start), y=np.mean(signal_before_ROI, axis=0),\n",
    "    error_y=dict(type='data', array=np.std(signal_before_ROI, axis=0))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='ROI (streched)',\n",
    "    x=np.arange(idx_start, idx_start+streched_ROI_win), y=np.mean(streched_ROI_signals, axis=0),\n",
    "    error_y=dict(type='data', array=np.std(streched_ROI_signals, axis=0))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='After ROI',\n",
    "    x=np.arange(idx_start+streched_ROI_win, idx_start+streched_ROI_win+20), y=np.mean(signals_after_ROI, axis=0),\n",
    "    error_y=dict(type='data', array=np.std(signals_after_ROI, axis=0))\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(title='Average mutation rate accross all reference', barmode='group', xaxis_title='nucleotide position', yaxis_title='mutation rate')\n",
    "fig.show()\n",
    "\n",
    "print('Average std before ROI', np.mean(np.std(signal_before_ROI, axis=0)))\n",
    "print('Average std in ROI', np.mean(np.std(streched_ROI_signals, axis=0)))\n",
    "print('Average std after ROI', np.mean(np.std(signals_after_ROI, axis=0)))\n",
    "\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/average_signal.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes on sampels:\n",
    "# 18 and 470\n",
    "# 19 and 472\n",
    "\n",
    "# 33, 36 are bad\n",
    "\n",
    "# Results\n",
    "# Across sample 18DMS\n",
    "# Average std before ROI 0.009616456641118194\n",
    "# Average std in ROI 0.019736332473797833\n",
    "# Average std after ROI 0.011510102386244694\n",
    "\n",
    "# Across all samples\n",
    "# Average std before ROI 0.01080475276617488\n",
    "# Average std in ROI 0.01984380795355725\n",
    "# Average std after ROI 0.014755924434694043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataset of signals for various sliding windows\n",
    "mu_thresh = 0.08\n",
    "\n",
    "def create_dataset(seq_list, signal_list, win_len):\n",
    "    # The dataset is a dictionary, each key corresponding to one possible window of bases\n",
    "\n",
    "    # Go over each sequence, extract sliding window array, and find matches with key window\n",
    "    dataset = {}\n",
    "    n_points = 0\n",
    "    for sequence, signal in zip(seq_list, signal_list):\n",
    "        idx_win = np.arange(len(sequence)-win_len+1)\n",
    "        seq_triplets = sequence[idx_win[:, np.newaxis] + np.arange(win_len)]\n",
    "        seq_triplets = seq_triplets[(seq_triplets[:, 1]=='A') | (seq_triplets[:, 1]=='C')]\n",
    "\n",
    "        # for seq_window, seq_key in zip(seq_window_set, seq_window_set_key):\n",
    "        for i, triplet in enumerate(seq_triplets):\n",
    "            key = ''.join(triplet)\n",
    "\n",
    "            if signal[i+1] < mu_thresh:\n",
    "                if key in dataset:\n",
    "                    dataset[key].append(signal[i+1])\n",
    "                else:\n",
    "                    dataset[key] = [signal[i+1]]\n",
    "                \n",
    "                n_points += 1\n",
    "            \n",
    "\n",
    "    print('Length of curated dataset', n_points)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, max_iter=1000, covariance_type = 'full')\n",
    "def fit_GMM(data):\n",
    "    gmm.fit(np.array(data).reshape(-1,1))\n",
    "    x_axis = np.linspace(min(data), max(data), 500)\n",
    "    pdf = np.zeros_like(x_axis)\n",
    "    for i_c in range(2):\n",
    "        pdf += norm.pdf(x_axis, gmm.means_[i_c], np.sqrt(float(gmm.covariances_[i_c])))*gmm.weights_[i_c]\n",
    "\n",
    "    return x_axis, pdf\n",
    "\n",
    "win_len = 3\n",
    "dataset = create_dataset(seqs_ROI, signals_ROI, win_len)\n",
    "print(\"Length of full dataset\", sequences.shape[0]*(sequences.shape[1]-(win_len-1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_signal = np.concatenate(signals_ROI).ravel()\n",
    "dataset['full'] = full_signal[full_signal < mu_thresh]\n",
    "\n",
    "dist = logGMM()\n",
    "dist.fit_logGMM(data=dataset['full'])\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Histogram(x=dataset['full'], histnorm='probability density', showlegend=False) )\n",
    "\n",
    "x_axis = np.linspace(min(dataset['full']), max(dataset['full']), 500)\n",
    "fig.add_trace( go.Scatter(x=x_axis, y=dist.get_pdf(x_axis), marker_color='red') )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Full dataset\"+' ({:.0f} points) | Mu low:{:.2e} | Mu mid: {:.2e} | Mu high: {:.2e}'.format(\n",
    "                            len(dataset['full']), \n",
    "                            dist.get_mode(0), dist.find_midpoint(), dist.get_mode(1)\n",
    "                            ),\n",
    "    xaxis_title=\"Mutation rate\",\n",
    "    yaxis_title=\"Probability density\")\n",
    "fig.update_yaxes(range=[0, 10*dist.get_pdf(dist.get_mode(1))[0]])\n",
    "\n",
    "mu_low.append(dist.get_mode(0))\n",
    "mu_mid.append(dist.find_midpoint())\n",
    "mu_high.append(dist.get_mode(1))\n",
    "\n",
    "fig.show()\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/logGMM/full_histogram.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['A'] = []\n",
    "dataset['C'] = []\n",
    "\n",
    "for key, value in dataset.items():\n",
    "    if len(key) == 3:\n",
    "        if key[1] =='A':\n",
    "            dataset['A'] += value\n",
    "\n",
    "        if key[1] =='C':\n",
    "            dataset['C'] += value\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "for i_b, key in enumerate(['A', 'C']):\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=dataset[key], histnorm='probability density', showlegend=False) , row=1, col=i_b+1)\n",
    "\n",
    "    x_axis = np.linspace(min(dataset[key]), max(dataset[key]), 500)\n",
    "    dist.fit_logGMM(data=dataset[key])\n",
    "\n",
    "    mu_low.append(dist.get_mode(0))\n",
    "    mu_mid.append(dist.find_midpoint())\n",
    "    mu_high.append(dist.get_mode(1))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=x_axis,\n",
    "            y=dist.get_pdf(x_axis),\n",
    "            showlegend=False,\n",
    "            marker_color = px.colors.qualitative.D3[2]\n",
    "        ), row=1, col=i_b+1)\n",
    "\n",
    "    fig.update_xaxes(title_text=key+' ({:.0f} points) | Mu low:{:.2e} | Mu mid: {:.2e} | Mu high: {:.2e}'.format(\n",
    "                            len(dataset[key]), \n",
    "                            dist.get_mode(0), dist.find_midpoint(), dist.get_mode(1)\n",
    "                            ), row=1, col=i_b+1)\n",
    "    fig.update_yaxes(range=[0, 10*dist.get_pdf(dist.get_mode(1))[0]], row=1, col=i_b+1)\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    title_text=\"Histogram of DMS signals for A and C\")\n",
    "fig.show()\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/logGMM/A_C_histogram.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_low = []\n",
    "mu_mid = []\n",
    "mu_high = []\n",
    "fig = make_subplots(rows=len(dataset)//2, cols=2)\n",
    "\n",
    "row_A = 1\n",
    "row_C = 1\n",
    "for i, key in enumerate(dataset.keys()):\n",
    "    if len(key) == 3:\n",
    "\n",
    "        col = 1 if key[1]=='A' else 2\n",
    "\n",
    "        if key[1]=='A':\n",
    "            row = row_A\n",
    "            row_A +=1\n",
    "            color= px.colors.qualitative.Plotly[1]\n",
    "        else:\n",
    "            row = row_C\n",
    "            row_C +=1\n",
    "            color= px.colors.qualitative.Plotly[0]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=dataset[key], showlegend=False, histnorm='probability density', marker_color=color) , row=row, col=col)\n",
    "\n",
    "        x_axis = np.linspace(min(dataset[key]), max(dataset[key]), 500)\n",
    "        dist.fit_logGMM(data=dataset[key])\n",
    "\n",
    "        mu_low.append(dist.get_mode(0))\n",
    "        mu_mid.append(dist.find_midpoint())\n",
    "        mu_high.append(dist.get_mode(1))\n",
    "\n",
    "        # mean.append([mean for _, mean in sorted(zip(gmm.means_.T[0], gmm.means_.T[0])) ])\n",
    "        # var.append([var for _, var in sorted(zip(gmm.means_.T[0], gmm.covariances_.T[0][0])) ])\n",
    "        # weight.append([w for _, w in sorted(zip(gmm.means_.T[0], gmm.weights_)) ])\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x_axis,\n",
    "            y=dist.get_pdf(x_axis),\n",
    "            showlegend=False,\n",
    "            marker_color = px.colors.qualitative.D3[2]\n",
    "        ), row=row, col=col)\n",
    "\n",
    "        fig.update_xaxes(title_text=key+' ({:.0f} points) | Mu low:{:.2e} | Mu mid: {:.2e} | Mu high: {:.2e}'.format(\n",
    "                            len(dataset[key]), \n",
    "                            dist.get_mode(0), dist.find_midpoint(), dist.get_mode(1)\n",
    "                            ), row=row, col=col)\n",
    "\n",
    "        fig.update_yaxes(range=[0, 10*dist.get_pdf(dist.get_mode(1))[0]], row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=4000,\n",
    "    width=1400,\n",
    "    title_text=\"Histogram of DMS signals for each triplet bases\")\n",
    "fig.show()\n",
    "\n",
    "mean = np.array(mean)\n",
    "var = np.array(var)\n",
    "weight = np.array(weight)\n",
    "# fig.write_html('/Users/alberic/Desktop/Pro/RouskinLab/projects/LaurenPaper/highthroughputcellularbiology/figs/logGMM/triplet_histogram.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for mu, v, w in zip(mean, var, weight):\n",
    "    fig.add_trace( go.Scatter(x = x_axis, y=norm.pdf(x_axis, mu[0], np.sqrt(v[0]))*w[0], marker_color='red', showlegend=False))\n",
    "    fig.add_trace( go.Scatter(x = x_axis, y=norm.pdf(x_axis, mu[1], np.sqrt(v[1]))*w[1], marker_color='blue', showlegend=False))\n",
    "\n",
    "# fig.update_yaxes(type='log', range=[0,2])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=2)\n",
    "\n",
    "for r, stat in enumerate([mean, var, weight]):\n",
    "\n",
    "    for i in range(stat.shape[1]):\n",
    "        fig.add_trace( go.Histogram(x=stat[:,i], showlegend=False) , row=r+1, col=i+1)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    width=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate(( ((np.random.rand(1000, 100) < 0.1).astype(int)), ((np.random.rand(1000, 100) < 0.2).astype(int)) ), axis=1)\n",
    "print(data.shape)\n",
    "muts_count = np.sum(data, axis=0)\n",
    "\n",
    "px.histogram(muts_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate(( ((np.random.rand(1000) < 0.1).astype(int)), ((np.random.rand(1000) < 0.3).astype(int)) ))\n",
    "\n",
    "muts_count = np.sum( np.random.choice(data, size=(2000, 1000)), axis=0 )\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=muts_count, histnorm='probability density', name='Boostraping'))\n",
    "\n",
    "x_axis = np.arange(320, 470).astype(int)\n",
    "mu_bin = np.count_nonzero(data)/len(data)\n",
    "fig.add_trace(  go.Scatter(x=x_axis, y=scipy.stats.binom.pmf(x_axis, len(data), mu_bin), name='Binomial'))\n",
    "fig.show()\n",
    "\n",
    "print('Binomial: mean {}, 95% confidance interval {}'.format(mu_bin, scipy.stats.binom.interval(0.95, len(data), mu_bin) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame([dataset]).T.reset_index()\n",
    "\n",
    "df_out = df_out.rename(columns={'index':'name', 0:'mu'})\n",
    "\n",
    "df_out['size'] = [len(mu) for mu in dataset.values()]\n",
    "\n",
    "df_out\n",
    "\n",
    "pd.DataFrame.to_csv(df_out, '/Users/alberic/Desktop/mu_triplet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame({'value':[key for key in dataset.keys()],\n",
    "                        'mu_low': mu_low,\n",
    "                        'mu_mid': mu_mid,\n",
    "                        'mu_high': mu_high})\n",
    "df_out['size'] = [len(mu) for mu in dataset.values()]\n",
    "pd.DataFrame.to_csv(df_out, '/Users/alberic/Desktop/mu_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in dataset.keys()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da229f0528e1c0d1c0b9dd42b2435d18e9f382f2b763d9e722ef981a0e650149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
