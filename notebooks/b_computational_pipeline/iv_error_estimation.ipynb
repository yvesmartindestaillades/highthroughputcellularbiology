{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error estimation\n",
    "**Note: first run of this cell takes a while**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "import util, config, plots\n",
    "import ipynbname\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of standard deviation w.r.t modification rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean of a binomial distribution with n=[500, 1000, 2000, 5000, 7500, 10000, 20000] and p=[0.01, 0.02, 0.05, 0.1]\n",
    "# use the standard deviation as a measure of error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = np.array([500, 1000, 2000, 5000, 7500, 10000, 20000])\n",
    "p = np.array([0.01, 0.02, 0.05, 0.1])\n",
    "p = p[::-1]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for p_ in p:\n",
    "    ax.errorbar(n, [p_]*n, label='p = {}'.format(p_), yerr=np.sqrt(n*p_*(1-p_)))\n",
    "ax.set(xlabel='number of reads', ylabel='std', title='Standard deviation of a binomial distribution')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barcode replicates simulation\n",
    "### Experimental: what distributino to expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The bootstrap always fits a binomial distribution, independent of the underlying distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Full dataset stats\n",
    "N, D = 10000, 1000\n",
    "data = np.concatenate(( (np.random.rand(N, D//2) < 0.02).astype(int), (np.random.rand(N, D//2) < 0.03).astype(int) ), axis=1)\n",
    "muts_count = np.sum(data, axis=0)\n",
    "\n",
    "\n",
    "# Stats on one column of data\n",
    "data_col = data[:, np.random.randint(0, D-1)]\n",
    "\n",
    "bootstrap_data = np.random.choice(data_col, size=(N, D), replace=True)\n",
    "\n",
    "muts_count_bs = np.sum(bootstrap_data, axis=0)\n",
    "\n",
    "# Make a Plotly subplot with the histogram of muts_count on the first row and the bootstrapping on the second row\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "\n",
    "fig.add_trace(go.Histogram(x=muts_count, histnorm='probability density', name='Original dataset' ), col=1, row=1)\n",
    "\n",
    "fig.add_trace(go.Histogram(x=muts_count_bs, histnorm='probability density', name='bootstrap data'), col=1, row=2)\n",
    "\n",
    "# Draw a binomial distribution on top of the histogram, with n=1000 and p estimated from the data\n",
    "from scipy.stats import binom\n",
    "x = np.arange(min(muts_count_bs), max(muts_count_bs)).astype(int)\n",
    "fig.add_trace(go.Scatter(x=x, y=binom.pmf(x, len(data_col), np.count_nonzero(data_col)/len(data_col)), mode='lines', name='binomial'), col=1, row=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_orc('../../bv/01_1_s22_reads_3043.orc')\n",
    "\n",
    "def process_data(data):\n",
    "    data = data.to_numpy(dtype=np.byte).astype(float)\n",
    "    data[data == 0] = 0\n",
    "    data[data < 0] = 128\n",
    "    data[data < 64] = 0\n",
    "    data[data > 0] = 1\n",
    "    return data\n",
    "\n",
    "data = process_data(pd.read_orc('../../bv/01_1_S22_reads_3081.orc'))\n",
    "sample = data[np.random.randint(0, data.shape[0], size=N)]\n",
    "observed_freq = sample.sum(axis=0)/N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap vs binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bootstrap\n",
    "### Define bootstrap function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(sample, n=1000):\n",
    "    \"\"\"\n",
    "    Bootstrap the sample\n",
    "    \"\"\"\n",
    "    n, r = sample.shape\n",
    "    res = np.zeros((n, r))\n",
    "    for i in range(n):\n",
    "        res[i] = sample[np.random.randint(0, n, n)].sum(axis=0)\n",
    "    return res\n",
    "\n",
    "def predict_confidence_interval_bootstrap(sample, bootstrap_iterations=1000):\n",
    "    bs = bootstrap(sample, n=bootstrap_iterations)\n",
    "    lower_bound, upper_bound = np.percentile(bs, [2.5, 97.5], axis=0)/size_sample\n",
    "    return lower_bound, upper_bound\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_confidence_interval_binomial_distribution(observed_freq, size_sample):\n",
    "    \"\"\"\n",
    "    Predict the confidence interval using the binomial distribution\n",
    "    \"\"\"\n",
    "    lower_bound = observed_freq - 1.96*np.sqrt(observed_freq*(1-observed_freq)/size_sample)\n",
    "    upper_bound = observed_freq + 1.96*np.sqrt(observed_freq*(1-observed_freq)/size_sample)\n",
    "    return lower_bound, upper_bound\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Wilson score \n",
    "### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilson(p, n, z = 1.96):\n",
    "    denominator = 1 + z**2/n\n",
    "    centre_adjusted_probability = p + z*z / (2*n)\n",
    "    adjusted_standard_deviation = np.sqrt((p*(1 - p) + z*z / (4*n)) / n)\n",
    "    \n",
    "    lower_bound = (centre_adjusted_probability - z*adjusted_standard_deviation) / denominator\n",
    "    upper_bound = (centre_adjusted_probability + z*adjusted_standard_deviation) / denominator\n",
    "    return (lower_bound, upper_bound)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clopper-Pearson \n",
    "### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clopper_pearson(*args):\n",
    "    return sm.stats.proportion_confint(*args, method='beta', alpha=0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agresti-Coull\n",
    "### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agresti_coull(*args):\n",
    "    return sm.stats.proportion_confint(*args, method='agresti_coull', alpha=0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def predict_confidence_interval_poisson(observed_freq, size_sample, alpha=0.05):\n",
    "    cov = size_sample\n",
    "    mut = observed_freq*size_sample\n",
    "    return 0.5*scipy.stats.chi2.ppf(alpha/2, df=2*mut)/cov, 0.5*scipy.stats.chi2.ppf(1-alpha/2, df=2*(mut+1))/cov\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compare the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_trials_per_dataset = 1\n",
    "bootstrap_iterations = 10\n",
    "methods = ['bootstrap', 'binomial', 'wilson', 'clopper_pearson', 'agresti_coull', 'poisson']\n",
    "size_samples = [500, 1000, 2000, 3000, 5000, 10000]\n",
    "\n",
    "failures_df = pd.DataFrame()\n",
    "size_df = pd.DataFrame()\n",
    "\n",
    "for size_sample in size_samples:\n",
    "    failures = {m:[] for m in methods}\n",
    "    size_ci = {m:[] for m in methods}\n",
    "    mut_rates_vector = []\n",
    "    failures_vector =  {m:[] for m in methods}\n",
    "    \n",
    "    for f in os.listdir('../../bv'):\n",
    "        \n",
    "        # read dataset\n",
    "        data = process_data(pd.read_orc('../../bv/' + f))\n",
    "        true_mutation_rate = data.sum(axis=0)/data.shape[0]\n",
    "\n",
    "        fail = {m:[] for m in methods}\n",
    "        size = {m:[] for m in methods}\n",
    "        \n",
    "        for _ in range(n_trials_per_dataset):\n",
    "            \n",
    "            # generate a new sample\n",
    "            sample = data[np.random.randint(0, data.shape[0], size=size_sample)]\n",
    "            observed_freq = sample.sum(axis=0)/size_sample\n",
    "            mut_rates_vector.append(true_mutation_rate)\n",
    "            \n",
    "            # count failures bootstrap\n",
    "            lb_bs, ub_bs = predict_confidence_interval_bootstrap(sample, bootstrap_iterations=bootstrap_iterations)\n",
    "            fail['bootstrap'].append(100*np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate).sum()/data.shape[1])\n",
    "            size['bootstrap'].append(np.mean(ub_bs - lb_bs))\n",
    "            failures_vector['bootstrap'].append(np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate))\n",
    "            \n",
    "            # count failures binomial\n",
    "            lb_bin, ub_bin = predict_confidence_interval_binomial_distribution(observed_freq, size_sample)\n",
    "            fail['binomial'].append(100*np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate).sum()/data.shape[1])\n",
    "            size['binomial'].append(np.mean(ub_bin - lb_bin))\n",
    "            failures_vector['binomial'].append(np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate))\n",
    "            \n",
    "            # count Wilson failures\n",
    "            lb_wilson, ub_wilson = wilson(observed_freq, size_sample)\n",
    "            fail['wilson'].append(100*np.logical_or(ub_wilson < true_mutation_rate, lb_wilson > true_mutation_rate).sum()/data.shape[1])\n",
    "            size['wilson'].append(np.mean(ub_wilson - lb_wilson))\n",
    "            failures_vector['wilson'].append(np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate))\n",
    "            \n",
    "            # count Clopper-Pearson failures\n",
    "            lb_cp, ub_cp = clopper_pearson(observed_freq*size_sample, size_sample)\n",
    "            fail['clopper_pearson'].append(100*np.logical_or(ub_cp < true_mutation_rate, lb_cp > true_mutation_rate).sum()/data.shape[1])\n",
    "            size['clopper_pearson'].append(np.mean(ub_cp - lb_cp))\n",
    "            failures_vector['clopper_pearson'].append(np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate))\n",
    "            \n",
    "            # count Agresti-Coull failures\n",
    "            lb_ac, ub_ac = agresti_coull(observed_freq*size_sample, size_sample)\n",
    "            fail['agresti_coull'].append(100*np.logical_or(ub_ac < true_mutation_rate, lb_ac > true_mutation_rate).sum()/data.shape[1])\n",
    "            size['agresti_coull'].append(np.mean(ub_ac - lb_ac))\n",
    "            failures_vector['agresti_coull'].append(np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate))\n",
    "            \n",
    "            # count Poisson failures\n",
    "            lb_poisson, ub_poisson = predict_confidence_interval_poisson(observed_freq, size_sample)\n",
    "            fail['poisson'].append(100*np.logical_or(ub_poisson < true_mutation_rate, lb_poisson > true_mutation_rate).sum()/data.shape[1])\n",
    "            size['poisson'].append(np.mean(ub_poisson - lb_poisson))\n",
    "            failures_vector['poisson'].append(np.logical_or(ub_bs < true_mutation_rate, lb_bs > true_mutation_rate))\n",
    "\n",
    "        for m in methods:\n",
    "            failures[m].append(fail[m])\n",
    "            size_ci[m].append(size[m])\n",
    "        #    print(f'{n_dataset}: {m}: {np.mean(failures[m][-1])}% failure rate')\n",
    "        #print('----------------------------------------------------------')\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'Bootstrap': np.array(failures['bootstrap']).flatten(), \n",
    "            'Binomial': np.array(failures['binomial']).flatten(), \n",
    "            'Wilson': np.array(failures['wilson']).flatten(),\n",
    "            'Clopper-Pearson': np.array(failures['clopper_pearson']).flatten(),\n",
    "            'Agresti-Coull': np.array(failures['agresti_coull']).flatten(),\n",
    "            'Poisson': np.array(failures['poisson']).flatten(),\n",
    "            'size_sample': size_sample,\n",
    "        })\n",
    "\n",
    "    failures_df = pd.concat([failures_df, df], axis=0)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'Bootstrap': np.array(size_ci['bootstrap']).flatten(), \n",
    "            'Binomial': np.array(size_ci['binomial']).flatten(), \n",
    "            'Wilson': np.array(size_ci['wilson']).flatten(),\n",
    "            'Clopper-Pearson': np.array(size_ci['clopper_pearson']).flatten(),\n",
    "            'Agresti-Coull': np.array(size_ci['agresti_coull']).flatten(),\n",
    "            'Poisson': np.array(size_ci['poisson']).flatten(),\n",
    "            'size_sample': size_sample        \n",
    "        })\n",
    "    size_df = pd.concat([size_df, df], axis=0)\n",
    "    \n",
    "fig = px.box(failures_df, y=[c for c in df.columns if c != 'size_sample'], color='size_sample', title='Failure rate of the confidence interval methods. n_bootstrap = {}, n_iter = {} iterations *{} datasets'.format(bootstrap_iterations, n_trials_per_dataset, len(os.listdir('../../bv'))))\n",
    "fig.update_yaxes(title_text=\"Failure rate (%)\")\n",
    "fig.update_xaxes(title_text=\"Method\")\n",
    "\n",
    "# add a horizontal line at y=5 all the way across the figure legend y=5 \n",
    "fig.add_shape(type=\"line\", x0=0, y0=5, x1=1, y1=5, line=dict(color=\"Green\", width=2, dash=\"dash\"), xref=\"paper\", yref=\"y\")\n",
    "\n",
    "# add a horizontal line at y=2.5\n",
    "fig.add_shape(type=\"line\", x0=0, y0=2.5, x1=1, y1=2.5, line=dict(color=\"Red\", width=2, dash=\"dash\", ), xref=\"paper\", yref=\"y\")\n",
    "\n",
    "util.save_plotly_fig(ipynbname.path(), '[A] Failure rate of the confidence interval methods', fig)\n",
    "\n",
    "fig.show()\n",
    "    \n",
    "fig = px.box(size_df, y=[c for c in df.columns if c != 'size_sample'], color='size_sample', title='Size of the confidence interval methods. n_bootstrap = {}, n_iter = {} iterations *{} datasets'.format(bootstrap_iterations, n_trials_per_dataset, len(os.listdir('../../bv'))))\n",
    "fig.update_yaxes(title_text=\"Size of the CI\")\n",
    "fig.update_xaxes(title_text=\"Method\")\n",
    "fig.show()\n",
    "\n",
    "# save to file\n",
    "util.save_plotly_fig(ipynbname.path(), '[B] Size of the confidence interval methods', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_rates_vector\n",
    "failures_vector\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Bootstrap': np.array(failures_vector['bootstrap']).flatten().astype(int), \n",
    "        'Binomial': np.array(failures_vector['binomial']).flatten().astype(int), \n",
    "        'Wilson': np.array(failures_vector['wilson']).flatten().astype(int), \n",
    "        'Clopper-Pearson': np.array(failures_vector['clopper_pearson']).flatten().astype(int), \n",
    "        'Agresti-Coull': np.array(failures_vector['agresti_coull']).flatten().astype(int), \n",
    "        'Poisson': np.array(failures_vector['poisson']).flatten().astype(int), \n",
    "        'size_sample': [s for s in size_samples for i in range(len(np.array(failures_vector['bootstrap']).flatten())//len(size_samples))]\n",
    "    }, \n",
    "    index = np.array(mut_rates_vector).flatten()\n",
    "    )\n",
    "\n",
    "\n",
    "df = df[df.index < 0.1].reset_index()\n",
    "#df = df[df.size_sample == 1000]\n",
    "\n",
    "# plot the index distributino\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df['index'], name='Mutation rate', marker_color='red', opacity=0.5))\n",
    "fig.update_layout(title='Mutation rate distribution', xaxis_title='Mutation rate', yaxis_title='Count')\n",
    "#fig.show()\n",
    "\n",
    "out = pd.DataFrame()\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'mut_rate'}, inplace=True)\n",
    "for size_sample, g in df.groupby('size_sample'):\n",
    "    # group g['index'] by 0.01 from 0 to 0.15\n",
    "    bins = np.arange(0, 100,1)\n",
    "    for col in df.columns:\n",
    "        if col != 'mut_rate' and col != 'size_sample' and col != 'level_0':\n",
    "            for mi, ma in zip(bins[:-1], bins[1:]):\n",
    "                out.loc[size_sample, col] = g[col].where((g['mut_rate'] >= mi) & (g['mut_rate'] < ma), inplace=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I tested the performance of different methods (bootstrap, binomial, wilson, copper-pearson, agresti-coull, poisson). I used the following method:\n",
    "1. load a real bitvector\n",
    "2. compute the true mutation rate of the bitvector\n",
    "3. draw n reads from the bitvector, n in [500, 1000, 2000, 3000, 5000, 10000]\n",
    "4. use each method to predict a 95% confidence interval\n",
    "5. for each base, count if the true mutation rate was in the confidence interval. Compute a failure rate. It should be 5%.\n",
    "6. reiterate the previous step 300 times for each value of n. You have now a distribution of the failure rate for each method and different values of n\n",
    "\n",
    "### The keys outputs I see:\n",
    "1. The most stable method across different values of N if `Wilson`.\n",
    "2. The best performers when using a large amount of reads (3000+) are `Bootstrap` and `Binomial` but are very sensitive to a lower amount of reads.\n",
    "3. Agresti, Clopper and Poisson “overkill” the confidence interval, so they are at ~3% error at 500 reads, which means the CI are less informative.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare replicates with different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from study_gen import study\n",
    "from plots import *\n",
    "from config import bio_replicates_samples\n",
    "\n",
    "for samples in bio_replicates_samples[4:]:\n",
    "    plots.biological_replicates_fisher_pearson(study, samples[:2])['fig'].show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da229f0528e1c0d1c0b9dd42b2435d18e9f382f2b763d9e722ef981a0e650149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
